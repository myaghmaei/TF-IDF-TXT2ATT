{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1747602f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import tensorflow_text as text\n",
    "from official.nlp import optimization  # to create AdamW optimizer\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.models import load_model\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.io\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "from sklearn.manifold import TSNE\n",
    "import seaborn as sns\n",
    "\n",
    "import pandas as pd\n",
    "import xlsxwriter\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.decomposition import SparsePCA\n",
    "\n",
    "tf.get_logger().setLevel('ERROR')\n",
    "\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aa199371",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7115, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>text</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>this article is about the herbivorous mammals....</td>\n",
       "      <td>Antelope</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>one new world species, the pronghorn of north ...</td>\n",
       "      <td>Antelope</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>the english word \"animal\" first appeared in 14...</td>\n",
       "      <td>Antelope</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>the word talopus and calopus, from latin, came...</td>\n",
       "      <td>Antelope</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>animal are not a cladistic or taxonomically de...</td>\n",
       "      <td>Antelope</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                               text     class\n",
       "0           0  this article is about the herbivorous mammals....  Antelope\n",
       "1           1  one new world species, the pronghorn of north ...  Antelope\n",
       "2           2  the english word \"animal\" first appeared in 14...  Antelope\n",
       "3           3  the word talopus and calopus, from latin, came...  Antelope\n",
       "4           4  animal are not a cladistic or taxonomically de...  Antelope"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#read the data into a pandas dataframe\n",
    "df = pd.read_csv(\"bert_data_withoutClassWord.csv\")\n",
    "print(df.shape)\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "105e94bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>text</th>\n",
       "      <th>class</th>\n",
       "      <th>class_num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>this article is about the herbivorous mammals....</td>\n",
       "      <td>Antelope</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>one new world species, the pronghorn of north ...</td>\n",
       "      <td>Antelope</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>the english word \"animal\" first appeared in 14...</td>\n",
       "      <td>Antelope</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>the word talopus and calopus, from latin, came...</td>\n",
       "      <td>Antelope</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>animal are not a cladistic or taxonomically de...</td>\n",
       "      <td>Antelope</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7110</th>\n",
       "      <td>7110</td>\n",
       "      <td>technology to use sponges as mouth protection ...</td>\n",
       "      <td>dolphin</td>\n",
       "      <td>49.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7111</th>\n",
       "      <td>7111</td>\n",
       "      <td>pesticides, heavy metals, plastics, and other ...</td>\n",
       "      <td>dolphin</td>\n",
       "      <td>49.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7112</th>\n",
       "      <td>7112</td>\n",
       "      <td>hundreds of orcas, animals and other members o...</td>\n",
       "      <td>dolphin</td>\n",
       "      <td>49.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7113</th>\n",
       "      <td>7113</td>\n",
       "      <td>captured orcas and animals are confined to tan...</td>\n",
       "      <td>dolphin</td>\n",
       "      <td>49.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7114</th>\n",
       "      <td>7114</td>\n",
       "      <td>marine parks may withhold up to 60 percent of ...</td>\n",
       "      <td>dolphin</td>\n",
       "      <td>49.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7115 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0                                               text     class  \\\n",
       "0              0  this article is about the herbivorous mammals....  Antelope   \n",
       "1              1  one new world species, the pronghorn of north ...  Antelope   \n",
       "2              2  the english word \"animal\" first appeared in 14...  Antelope   \n",
       "3              3  the word talopus and calopus, from latin, came...  Antelope   \n",
       "4              4  animal are not a cladistic or taxonomically de...  Antelope   \n",
       "...          ...                                                ...       ...   \n",
       "7110        7110  technology to use sponges as mouth protection ...   dolphin   \n",
       "7111        7111  pesticides, heavy metals, plastics, and other ...   dolphin   \n",
       "7112        7112  hundreds of orcas, animals and other members o...   dolphin   \n",
       "7113        7113  captured orcas and animals are confined to tan...   dolphin   \n",
       "7114        7114  marine parks may withhold up to 60 percent of ...   dolphin   \n",
       "\n",
       "      class_num  \n",
       "0           0.0  \n",
       "1           0.0  \n",
       "2           0.0  \n",
       "3           0.0  \n",
       "4           0.0  \n",
       "...         ...  \n",
       "7110       49.0  \n",
       "7111       49.0  \n",
       "7112       49.0  \n",
       "7113       49.0  \n",
       "7114       49.0  \n",
       "\n",
       "[7115 rows x 4 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Add the new column which gives a unique number to each of these labels \n",
    "\n",
    "j = 0\n",
    "for i in df['class'].unique():\n",
    "    df.loc[df['class'] == i, ['class_num']] = j\n",
    "    j += 1\n",
    "\n",
    "#checking the results \n",
    "df.head(50000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bc496ea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df.text, \n",
    "    df.class_num, \n",
    "    test_size=0.1, # 20% samples will go to test dataset\n",
    "    random_state=2022,\n",
    "    stratify=df.class_num\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac8233f6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9b681cc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "embbeding_size = 4000\n",
    "clustering_count = 3\n",
    "numof_embb = 2\n",
    "att_size = embbeding_size * clustering_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cb988e97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACC: 0.43679775280898875\n",
      "ACC: 0.4438202247191011\n",
      "ACC: 0.425561797752809\n",
      "ACC: 0.44803370786516855\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [19]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m#using pca\u001b[39;00m\n\u001b[0;32m     13\u001b[0m S_pca \u001b[38;5;241m=\u001b[39m SparsePCA(n_components\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1500\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m---> 14\u001b[0m X_train_PCA \u001b[38;5;241m=\u001b[39m \u001b[43mS_pca\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train_vectorized\u001b[49m\u001b[43m)\u001b[49m    \n\u001b[0;32m     16\u001b[0m clf \u001b[38;5;241m=\u001b[39m RandomForestClassifier()\n\u001b[0;32m     17\u001b[0m clf\u001b[38;5;241m.\u001b[39mfit(X_train_PCA, y_train)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\piptext\\lib\\site-packages\\sklearn\\base.py:867\u001b[0m, in \u001b[0;36mTransformerMixin.fit_transform\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    863\u001b[0m \u001b[38;5;66;03m# non-optimized default implementation; override when a better\u001b[39;00m\n\u001b[0;32m    864\u001b[0m \u001b[38;5;66;03m# method is possible for a given clustering algorithm\u001b[39;00m\n\u001b[0;32m    865\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    866\u001b[0m     \u001b[38;5;66;03m# fit method of arity 1 (unsupervised transformation)\u001b[39;00m\n\u001b[1;32m--> 867\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_params\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mtransform(X)\n\u001b[0;32m    868\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    869\u001b[0m     \u001b[38;5;66;03m# fit method of arity 2 (supervised transformation)\u001b[39;00m\n\u001b[0;32m    870\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfit(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\u001b[38;5;241m.\u001b[39mtransform(X)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\piptext\\lib\\site-packages\\sklearn\\decomposition\\_sparse_pca.py:186\u001b[0m, in \u001b[0;36mSparsePCA.fit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    184\u001b[0m code_init \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mV_init\u001b[38;5;241m.\u001b[39mT \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mV_init \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    185\u001b[0m dict_init \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mU_init\u001b[38;5;241m.\u001b[39mT \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mU_init \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m--> 186\u001b[0m Vt, _, E, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_iter_ \u001b[38;5;241m=\u001b[39m \u001b[43mdict_learning\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    187\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mT\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    188\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_components\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    189\u001b[0m \u001b[43m    \u001b[49m\u001b[43malpha\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43malpha\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    190\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtol\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtol\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    191\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_iter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_iter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    192\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    193\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    194\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    195\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrandom_state\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    196\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcode_init\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcode_init\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    197\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdict_init\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdict_init\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    198\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_n_iter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    199\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    200\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcomponents_ \u001b[38;5;241m=\u001b[39m Vt\u001b[38;5;241m.\u001b[39mT\n\u001b[0;32m    201\u001b[0m components_norm \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mlinalg\u001b[38;5;241m.\u001b[39mnorm(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcomponents_, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)[:, np\u001b[38;5;241m.\u001b[39mnewaxis]\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\piptext\\lib\\site-packages\\sklearn\\decomposition\\_dict_learning.py:678\u001b[0m, in \u001b[0;36mdict_learning\u001b[1;34m(X, n_components, alpha, max_iter, tol, method, n_jobs, dict_init, code_init, callback, verbose, random_state, return_n_iter, positive_dict, positive_code, method_max_iter)\u001b[0m\n\u001b[0;32m    672\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[0;32m    673\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIteration \u001b[39m\u001b[38;5;132;01m% 3i\u001b[39;00m\u001b[38;5;124m (elapsed time: \u001b[39m\u001b[38;5;132;01m% 3i\u001b[39;00m\u001b[38;5;124ms, \u001b[39m\u001b[38;5;132;01m% 4.1f\u001b[39;00m\u001b[38;5;124mmn, current cost \u001b[39m\u001b[38;5;132;01m% 7.3f\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    674\u001b[0m         \u001b[38;5;241m%\u001b[39m (ii, dt, dt \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m60\u001b[39m, current_cost)\n\u001b[0;32m    675\u001b[0m     )\n\u001b[0;32m    677\u001b[0m \u001b[38;5;66;03m# Update code\u001b[39;00m\n\u001b[1;32m--> 678\u001b[0m code \u001b[38;5;241m=\u001b[39m \u001b[43msparse_encode\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    679\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    680\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdictionary\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    681\u001b[0m \u001b[43m    \u001b[49m\u001b[43malgorithm\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    682\u001b[0m \u001b[43m    \u001b[49m\u001b[43malpha\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43malpha\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    683\u001b[0m \u001b[43m    \u001b[49m\u001b[43minit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    684\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    685\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpositive\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpositive_code\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    686\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_iter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmethod_max_iter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    687\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    688\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    690\u001b[0m \u001b[38;5;66;03m# Update dictionary in place\u001b[39;00m\n\u001b[0;32m    691\u001b[0m _update_dict(\n\u001b[0;32m    692\u001b[0m     dictionary,\n\u001b[0;32m    693\u001b[0m     X,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    697\u001b[0m     positive\u001b[38;5;241m=\u001b[39mpositive_dict,\n\u001b[0;32m    698\u001b[0m )\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\piptext\\lib\\site-packages\\sklearn\\decomposition\\_dict_learning.py:373\u001b[0m, in \u001b[0;36msparse_encode\u001b[1;34m(X, dictionary, gram, cov, algorithm, n_nonzero_coefs, alpha, copy_cov, init, max_iter, n_jobs, check_input, verbose, positive)\u001b[0m\n\u001b[0;32m    370\u001b[0m         regularization \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1.0\u001b[39m\n\u001b[0;32m    372\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m effective_n_jobs(n_jobs) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m algorithm \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthreshold\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 373\u001b[0m     code \u001b[38;5;241m=\u001b[39m \u001b[43m_sparse_encode\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    374\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    375\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdictionary\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    376\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgram\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    377\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcov\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcov\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    378\u001b[0m \u001b[43m        \u001b[49m\u001b[43malgorithm\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43malgorithm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    379\u001b[0m \u001b[43m        \u001b[49m\u001b[43mregularization\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mregularization\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    380\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcopy_cov\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy_cov\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    381\u001b[0m \u001b[43m        \u001b[49m\u001b[43minit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    382\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_iter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_iter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    383\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcheck_input\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    384\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    385\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpositive\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpositive\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    386\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    387\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m code\n\u001b[0;32m    389\u001b[0m \u001b[38;5;66;03m# Enter parallel code block\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\piptext\\lib\\site-packages\\sklearn\\decomposition\\_dict_learning.py:156\u001b[0m, in \u001b[0;36m_sparse_encode\u001b[1;34m(X, dictionary, gram, cov, algorithm, regularization, copy_cov, init, max_iter, check_input, verbose, positive)\u001b[0m\n\u001b[0;32m    144\u001b[0m     \u001b[38;5;66;03m# Not passing in verbose=max(0, verbose-1) because Lars.fit already\u001b[39;00m\n\u001b[0;32m    145\u001b[0m     \u001b[38;5;66;03m# corrects the verbosity level.\u001b[39;00m\n\u001b[0;32m    146\u001b[0m     lasso_lars \u001b[38;5;241m=\u001b[39m LassoLars(\n\u001b[0;32m    147\u001b[0m         alpha\u001b[38;5;241m=\u001b[39malpha,\n\u001b[0;32m    148\u001b[0m         fit_intercept\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    154\u001b[0m         max_iter\u001b[38;5;241m=\u001b[39mmax_iter,\n\u001b[0;32m    155\u001b[0m     )\n\u001b[1;32m--> 156\u001b[0m     \u001b[43mlasso_lars\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdictionary\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mT\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mT\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mXy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcov\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    157\u001b[0m     new_code \u001b[38;5;241m=\u001b[39m lasso_lars\u001b[38;5;241m.\u001b[39mcoef_\n\u001b[0;32m    158\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\piptext\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:1128\u001b[0m, in \u001b[0;36mLars.fit\u001b[1;34m(self, X, y, Xy)\u001b[0m\n\u001b[0;32m   1125\u001b[0m     noise \u001b[38;5;241m=\u001b[39m rng\u001b[38;5;241m.\u001b[39muniform(high\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mjitter, size\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m(y))\n\u001b[0;32m   1126\u001b[0m     y \u001b[38;5;241m=\u001b[39m y \u001b[38;5;241m+\u001b[39m noise\n\u001b[1;32m-> 1128\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1129\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1130\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1131\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_iter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_iter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1132\u001b[0m \u001b[43m    \u001b[49m\u001b[43malpha\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43malpha\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1133\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfit_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1134\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnormalize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_normalize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1135\u001b[0m \u001b[43m    \u001b[49m\u001b[43mXy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mXy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1136\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1138\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\piptext\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:1063\u001b[0m, in \u001b[0;36mLars._fit\u001b[1;34m(self, X, y, max_iter, alpha, fit_path, normalize, Xy)\u001b[0m\n\u001b[0;32m   1061\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_targets):\n\u001b[0;32m   1062\u001b[0m     this_Xy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mif\u001b[39;00m Xy \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m Xy[:, k]\n\u001b[1;32m-> 1063\u001b[0m     alphas, _, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcoef_[k], n_iter_ \u001b[38;5;241m=\u001b[39m \u001b[43mlars_path\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1064\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1065\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1066\u001b[0m \u001b[43m        \u001b[49m\u001b[43mGram\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mGram\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1067\u001b[0m \u001b[43m        \u001b[49m\u001b[43mXy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mthis_Xy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1068\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcopy_X\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcopy_X\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1069\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcopy_Gram\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   1070\u001b[0m \u001b[43m        \u001b[49m\u001b[43malpha_min\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43malpha\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1071\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1072\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mmax\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1073\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_iter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_iter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1074\u001b[0m \u001b[43m        \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1075\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   1076\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_n_iter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   1077\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpositive\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpositive\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1078\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1079\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39malphas_\u001b[38;5;241m.\u001b[39mappend(alphas)\n\u001b[0;32m   1080\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_iter_\u001b[38;5;241m.\u001b[39mappend(n_iter_)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\piptext\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:169\u001b[0m, in \u001b[0;36mlars_path\u001b[1;34m(X, y, Xy, Gram, max_iter, alpha_min, method, copy_X, eps, copy_Gram, verbose, return_path, return_n_iter, positive)\u001b[0m\n\u001b[0;32m    164\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m X \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m Gram \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    165\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    166\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX cannot be None if Gram is not None\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    167\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUse lars_path_gram to avoid passing X and y.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    168\u001b[0m     )\n\u001b[1;32m--> 169\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_lars_path_solver\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    170\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    171\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    172\u001b[0m \u001b[43m    \u001b[49m\u001b[43mXy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mXy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    173\u001b[0m \u001b[43m    \u001b[49m\u001b[43mGram\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mGram\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    174\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_samples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    175\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_iter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_iter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    176\u001b[0m \u001b[43m    \u001b[49m\u001b[43malpha_min\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43malpha_min\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    177\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    178\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcopy_X\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy_X\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    179\u001b[0m \u001b[43m    \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    180\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcopy_Gram\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy_Gram\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    181\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    182\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    183\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_n_iter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_n_iter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    184\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpositive\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpositive\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    185\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\piptext\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:482\u001b[0m, in \u001b[0;36m_lars_path_solver\u001b[1;34m(X, y, Xy, Gram, n_samples, max_iter, alpha_min, method, copy_X, eps, copy_Gram, verbose, return_path, return_n_iter, positive)\u001b[0m\n\u001b[0;32m    480\u001b[0m         Gram \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    481\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m copy_Gram:\n\u001b[1;32m--> 482\u001b[0m     Gram \u001b[38;5;241m=\u001b[39m \u001b[43mGram\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    484\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m Gram \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    485\u001b[0m     n_features \u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "acc = 0\n",
    "\n",
    "while 0.519 > acc:\n",
    "    \n",
    "    vectorizer = TfidfVectorizer(max_features = embbeding_size).fit(X_train)\n",
    "    \n",
    "    len(vectorizer.get_feature_names_out())\n",
    "    \n",
    "    X_train_vectorized = vectorizer.transform(X_train)\n",
    "    X_train_vectorized = X_train_vectorized.toarray()\n",
    "    \n",
    "    #using pca\n",
    "    S_pca = SparsePCA(n_components=1500, random_state=0)\n",
    "    X_train_PCA = S_pca.fit_transform(X_train_vectorized)    \n",
    "    \n",
    "    clf = RandomForestClassifier()\n",
    "    clf.fit(X_train_PCA, y_train)\n",
    "    \n",
    "    #transforming X_test\n",
    "    X_test_vectorized = vectorizer.transform(X_test)\n",
    "    X_test_vectorized = X_test_vectorized.toarray()\n",
    "    X_test_PCA = S_pca.transform(X_test_vectorized)\n",
    "    \n",
    "    predictions = clf.predict(X_test_PCA)\n",
    "    acc = accuracy_score(y_test, predictions)\n",
    "    print(\"ACC:\", accuracy_score(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "233e4f98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "[0. 0. 0. ... 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "# vectorizer.transform() is our emb creator\n",
    "\n",
    "all_atts = vectorizer.transform(df.text).toarray()\n",
    "print(type(all_atts))\n",
    "print(all_atts[0])\n",
    "all_labels = df['class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9172ab1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4000,)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_atts[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b1fd9a21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>3991</th>\n",
       "      <th>3992</th>\n",
       "      <th>3993</th>\n",
       "      <th>3994</th>\n",
       "      <th>3995</th>\n",
       "      <th>3996</th>\n",
       "      <th>3997</th>\n",
       "      <th>3998</th>\n",
       "      <th>3999</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Antelope</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Antelope</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Antelope</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Antelope</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Antelope</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7110</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>dolphin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7111</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>dolphin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7112</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>dolphin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7113</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>dolphin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7114</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>dolphin</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7115 rows × 4001 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0    1    2    3    4    5    6    7    8    9  ...  3991  3992  3993  \\\n",
       "0     0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   0.0   0.0   \n",
       "1     0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   0.0   0.0   \n",
       "2     0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   0.0   0.0   \n",
       "3     0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   0.0   0.0   \n",
       "4     0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   0.0   0.0   \n",
       "...   ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...   ...   ...   ...   \n",
       "7110  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   0.0   0.0   \n",
       "7111  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   0.0   0.0   \n",
       "7112  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   0.0   0.0   \n",
       "7113  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   0.0   0.0   \n",
       "7114  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   0.0   0.0   \n",
       "\n",
       "      3994  3995  3996  3997  3998  3999    labels  \n",
       "0      0.0   0.0   0.0   0.0   0.0   0.0  Antelope  \n",
       "1      0.0   0.0   0.0   0.0   0.0   0.0  Antelope  \n",
       "2      0.0   0.0   0.0   0.0   0.0   0.0  Antelope  \n",
       "3      0.0   0.0   0.0   0.0   0.0   0.0  Antelope  \n",
       "4      0.0   0.0   0.0   0.0   0.0   0.0  Antelope  \n",
       "...    ...   ...   ...   ...   ...   ...       ...  \n",
       "7110   0.0   0.0   0.0   0.0   0.0   0.0   dolphin  \n",
       "7111   0.0   0.0   0.0   0.0   0.0   0.0   dolphin  \n",
       "7112   0.0   0.0   0.0   0.0   0.0   0.0   dolphin  \n",
       "7113   0.0   0.0   0.0   0.0   0.0   0.0   dolphin  \n",
       "7114   0.0   0.0   0.0   0.0   0.0   0.0   dolphin  \n",
       "\n",
       "[7115 rows x 4001 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#print(all_atts)\n",
    "data = pd.DataFrame(all_atts)\n",
    "\n",
    "data['labels'] = all_labels\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "23d09fbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def att_generator(embbedings, numof_embb=numof_embb, num_clusters=clustering_count):\n",
    "\n",
    "    #clustering embbedings\n",
    "    km = KMeans(n_clusters=num_clusters)\n",
    "    clustering_predictions = km.fit_predict(embbedings)\n",
    "    \n",
    "    #convert to dataframe for ease of use\n",
    "    df = pd.DataFrame(embbedings)\n",
    "    \n",
    "    #include the cluster labels\n",
    "    df[\"clusters\"] = clustering_predictions\n",
    "    \n",
    "    #creating the attribute array\n",
    "    the_attribute = np.array([])\n",
    "    \n",
    "    for i in np.unique(clustering_predictions):\n",
    "        \n",
    "        cluster_embbedings = df[df[\"clusters\"] == i]\n",
    "        cluster_embbedings = cluster_embbedings.drop([\"clusters\"], axis=1) \n",
    "        cluster_embbedings_nparray = cluster_embbedings.to_numpy()\n",
    "        \n",
    "        cluster_mean = np.mean(cluster_embbedings_nparray, axis=0)\n",
    "        emb_distances = np.array([])\n",
    "        \n",
    "        #calculating each embbeding distance from its cluster mean and selecting the closest one to the mean\n",
    "        for i in range(cluster_embbedings_nparray.shape[0]):\n",
    "            \n",
    "            dist = np.linalg.norm(cluster_mean - cluster_embbedings_nparray[i])\n",
    "            emb_distances = np.append(emb_distances, dist)\n",
    "            \n",
    "            \n",
    "        \n",
    "        emb_distances = np.reshape(emb_distances, (-1, 1))\n",
    "        #print(cluster_embbedings_nparray.shape, emb_distances.shape)\n",
    "        temp = np.concatenate((cluster_embbedings_nparray, emb_distances), axis=1)\n",
    "        #print(temp.shape)\n",
    "        temp = temp[temp[:, -1].argsort()]\n",
    "        #print(temp[:, -1])\n",
    "        sorted_embbedings = np.delete(temp, -1, 1)\n",
    "        #print(sorted_embbedings.shape)\n",
    "        \n",
    "        the_attribute = np.concatenate((the_attribute, sorted_embbedings[0]), axis=0)\n",
    "        print(the_attribute.shape)\n",
    "\n",
    "    \n",
    "    return the_attribute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d0f7ee4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MOHSEN\\anaconda3\\envs\\piptext\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1334: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4000,)\n",
      "(8000,)\n",
      "(12000,)\n",
      "(4000,)\n",
      "(8000,)\n",
      "(12000,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MOHSEN\\anaconda3\\envs\\piptext\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1334: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n",
      "C:\\Users\\MOHSEN\\anaconda3\\envs\\piptext\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1334: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4000,)\n",
      "(8000,)\n",
      "(12000,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MOHSEN\\anaconda3\\envs\\piptext\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1334: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n",
      "C:\\Users\\MOHSEN\\anaconda3\\envs\\piptext\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1334: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4000,)\n",
      "(8000,)\n",
      "(12000,)\n",
      "(4000,)\n",
      "(8000,)\n",
      "(12000,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MOHSEN\\anaconda3\\envs\\piptext\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1334: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4000,)\n",
      "(8000,)\n",
      "(12000,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MOHSEN\\anaconda3\\envs\\piptext\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1334: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4000,)\n",
      "(8000,)\n",
      "(12000,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MOHSEN\\anaconda3\\envs\\piptext\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1334: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4000,)\n",
      "(8000,)\n",
      "(12000,)\n",
      "(4000,)\n",
      "(8000,)\n",
      "(12000,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MOHSEN\\anaconda3\\envs\\piptext\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1334: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n",
      "C:\\Users\\MOHSEN\\anaconda3\\envs\\piptext\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1334: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4000,)\n",
      "(8000,)\n",
      "(12000,)\n",
      "(4000,)\n",
      "(8000,)\n",
      "(12000,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MOHSEN\\anaconda3\\envs\\piptext\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1334: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n",
      "C:\\Users\\MOHSEN\\anaconda3\\envs\\piptext\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1334: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4000,)\n",
      "(8000,)\n",
      "(12000,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MOHSEN\\anaconda3\\envs\\piptext\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1334: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4000,)\n",
      "(8000,)\n",
      "(12000,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MOHSEN\\anaconda3\\envs\\piptext\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1334: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4000,)\n",
      "(8000,)\n",
      "(12000,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MOHSEN\\anaconda3\\envs\\piptext\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1334: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4000,)\n",
      "(8000,)\n",
      "(12000,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MOHSEN\\anaconda3\\envs\\piptext\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1334: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4000,)\n",
      "(8000,)\n",
      "(12000,)\n",
      "(4000,)\n",
      "(8000,)\n",
      "(12000,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MOHSEN\\anaconda3\\envs\\piptext\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1334: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n",
      "C:\\Users\\MOHSEN\\anaconda3\\envs\\piptext\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1334: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4000,)\n",
      "(8000,)\n",
      "(12000,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MOHSEN\\anaconda3\\envs\\piptext\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1334: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4000,)\n",
      "(8000,)\n",
      "(12000,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MOHSEN\\anaconda3\\envs\\piptext\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1334: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4000,)\n",
      "(8000,)\n",
      "(12000,)\n",
      "(4000,)\n",
      "(8000,)\n",
      "(12000,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MOHSEN\\anaconda3\\envs\\piptext\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1334: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n",
      "C:\\Users\\MOHSEN\\anaconda3\\envs\\piptext\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1334: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4000,)\n",
      "(8000,)\n",
      "(12000,)\n",
      "(4000,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MOHSEN\\anaconda3\\envs\\piptext\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1334: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8000,)\n",
      "(12000,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MOHSEN\\anaconda3\\envs\\piptext\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1334: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4000,)\n",
      "(8000,)\n",
      "(12000,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MOHSEN\\anaconda3\\envs\\piptext\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1334: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4000,)\n",
      "(8000,)\n",
      "(12000,)\n",
      "(4000,)\n",
      "(8000,)\n",
      "(12000,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MOHSEN\\anaconda3\\envs\\piptext\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1334: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n",
      "C:\\Users\\MOHSEN\\anaconda3\\envs\\piptext\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1334: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4000,)\n",
      "(8000,)\n",
      "(12000,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MOHSEN\\anaconda3\\envs\\piptext\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1334: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n",
      "C:\\Users\\MOHSEN\\anaconda3\\envs\\piptext\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1334: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4000,)\n",
      "(8000,)\n",
      "(12000,)\n",
      "(4000,)\n",
      "(8000,)\n",
      "(12000,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MOHSEN\\anaconda3\\envs\\piptext\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1334: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4000,)\n",
      "(8000,)\n",
      "(12000,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MOHSEN\\anaconda3\\envs\\piptext\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1334: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4000,)\n",
      "(8000,)\n",
      "(12000,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MOHSEN\\anaconda3\\envs\\piptext\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1334: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4000,)\n",
      "(8000,)\n",
      "(12000,)\n",
      "(4000,)\n",
      "(8000,)\n",
      "(12000,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MOHSEN\\anaconda3\\envs\\piptext\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1334: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n",
      "C:\\Users\\MOHSEN\\anaconda3\\envs\\piptext\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1334: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4000,)\n",
      "(8000,)\n",
      "(12000,)\n",
      "(4000,)\n",
      "(8000,)\n",
      "(12000,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MOHSEN\\anaconda3\\envs\\piptext\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1334: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n",
      "C:\\Users\\MOHSEN\\anaconda3\\envs\\piptext\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1334: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4000,)\n",
      "(8000,)\n",
      "(12000,)\n",
      "(4000,)\n",
      "(8000,)\n",
      "(12000,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MOHSEN\\anaconda3\\envs\\piptext\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1334: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n",
      "C:\\Users\\MOHSEN\\anaconda3\\envs\\piptext\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1334: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4000,)\n",
      "(8000,)\n",
      "(12000,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MOHSEN\\anaconda3\\envs\\piptext\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1334: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4000,)\n",
      "(8000,)\n",
      "(12000,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MOHSEN\\anaconda3\\envs\\piptext\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1334: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n",
      "C:\\Users\\MOHSEN\\anaconda3\\envs\\piptext\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1334: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4000,)\n",
      "(8000,)\n",
      "(12000,)\n",
      "(4000,)\n",
      "(8000,)\n",
      "(12000,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MOHSEN\\anaconda3\\envs\\piptext\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1334: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n",
      "C:\\Users\\MOHSEN\\anaconda3\\envs\\piptext\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1334: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4000,)\n",
      "(8000,)\n",
      "(12000,)\n",
      "(4000,)\n",
      "(8000,)\n",
      "(12000,)\n",
      "(4000,)\n",
      "(8000,)\n",
      "(12000,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MOHSEN\\anaconda3\\envs\\piptext\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1334: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n",
      "C:\\Users\\MOHSEN\\anaconda3\\envs\\piptext\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1334: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4000,)\n",
      "(8000,)\n",
      "(12000,)\n",
      "(4000,)\n",
      "(8000,)\n",
      "(12000,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MOHSEN\\anaconda3\\envs\\piptext\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1334: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n",
      "C:\\Users\\MOHSEN\\anaconda3\\envs\\piptext\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1334: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4000,)\n",
      "(8000,)\n",
      "(12000,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MOHSEN\\anaconda3\\envs\\piptext\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1334: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4000,)\n",
      "(8000,)\n",
      "(12000,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MOHSEN\\anaconda3\\envs\\piptext\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1334: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4000,)\n",
      "(8000,)\n",
      "(12000,)\n",
      "(4000,)\n",
      "(8000,)\n",
      "(12000,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MOHSEN\\anaconda3\\envs\\piptext\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1334: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "unique_classes = data[\"labels\"].unique()\n",
    "attribute_array = np.zeros([1, att_size])\n",
    "\n",
    "for i in unique_classes:\n",
    "    \n",
    "    class_embbedings = data.loc[data['labels'] == i]\n",
    "    class_embbedings = class_embbedings.drop(['labels'], axis=1)    \n",
    "\n",
    "    myatt = att_generator(class_embbedings)\n",
    "    myatt = myatt.reshape(1, att_size)\n",
    "    \n",
    "    attribute_array = np.append(attribute_array, myatt, axis=0)\n",
    "\n",
    "attribute_array = np.delete(attribute_array, 0, 0)\n",
    "attribute_array = attribute_array.transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b30920df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12000, 50)\n"
     ]
    }
   ],
   "source": [
    "the_mat_file = scipy.io.loadmat('att_splits_AWA2.mat')\n",
    "the_mat_file[\"att\"] = attribute_array\n",
    "\n",
    "print(the_mat_file[\"att\"].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0cf46dde",
   "metadata": {},
   "outputs": [],
   "source": [
    "scipy.io.savemat('tf-idf_4000_embClust(3,1).mat', the_mat_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "0653d224",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>embbedings</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(0, 3815)\\t0.2116568711329839\\n  (0, 3798)\\t...</td>\n",
       "      <td>Antelope</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(0, 3972)\\t0.190382191693978\\n  (0, 3725)\\t0...</td>\n",
       "      <td>Antelope</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(0, 3966)\\t0.36810011017665584\\n  (0, 3925)\\...</td>\n",
       "      <td>Antelope</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(0, 3966)\\t0.189929209485221\\n  (0, 3878)\\t0...</td>\n",
       "      <td>Antelope</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(0, 3954)\\t0.1671060571283198\\n  (0, 3758)\\t...</td>\n",
       "      <td>Antelope</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>(0, 3796)\\t0.15071770983014868\\n  (0, 3758)\\...</td>\n",
       "      <td>Antelope</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186</th>\n",
       "      <td>(0, 3942)\\t0.13666177470169633\\n  (0, 3595)\\...</td>\n",
       "      <td>Antelope</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>(0, 3883)\\t0.16809701621305914\\n  (0, 3595)\\...</td>\n",
       "      <td>Antelope</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>(0, 3798)\\t0.26935198636538843\\n  (0, 3747)\\...</td>\n",
       "      <td>Antelope</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>(0, 3995)\\t0.1542376039092315\\n  (0, 3993)\\t...</td>\n",
       "      <td>Antelope</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>190 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            embbedings    labels\n",
       "0      (0, 3815)\\t0.2116568711329839\\n  (0, 3798)\\t...  Antelope\n",
       "1      (0, 3972)\\t0.190382191693978\\n  (0, 3725)\\t0...  Antelope\n",
       "2      (0, 3966)\\t0.36810011017665584\\n  (0, 3925)\\...  Antelope\n",
       "3      (0, 3966)\\t0.189929209485221\\n  (0, 3878)\\t0...  Antelope\n",
       "4      (0, 3954)\\t0.1671060571283198\\n  (0, 3758)\\t...  Antelope\n",
       "..                                                 ...       ...\n",
       "185    (0, 3796)\\t0.15071770983014868\\n  (0, 3758)\\...  Antelope\n",
       "186    (0, 3942)\\t0.13666177470169633\\n  (0, 3595)\\...  Antelope\n",
       "187    (0, 3883)\\t0.16809701621305914\\n  (0, 3595)\\...  Antelope\n",
       "188    (0, 3798)\\t0.26935198636538843\\n  (0, 3747)\\...  Antelope\n",
       "189    (0, 3995)\\t0.1542376039092315\\n  (0, 3993)\\t...  Antelope\n",
       "\n",
       "[190 rows x 2 columns]"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#data = data.rename(columns={\"0\": \"embbedings\"})\n",
    "#data\n",
    "data.loc[data['labels'] == 'Antelope']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a18d31d",
   "metadata": {},
   "source": [
    "# obtain att"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "429e8913",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(r'bert_data_withoutClassWord.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "c47834dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       Antelope\n",
       "1       Antelope\n",
       "2       Antelope\n",
       "3       Antelope\n",
       "4       Antelope\n",
       "          ...   \n",
       "7110     dolphin\n",
       "7111     dolphin\n",
       "7112     dolphin\n",
       "7113     dolphin\n",
       "7114     dolphin\n",
       "Name: class, Length: 7115, dtype: object"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "45ffedde",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(85, 50)"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "the_mat_file = scipy.io.loadmat('att_splits_AWA2.mat')\n",
    "the_mat_file['att'].shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "piptext",
   "language": "python",
   "name": "piptext"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
