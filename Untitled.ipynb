{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ad28d458",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "corpus = [\n",
    "    \"Thor eating pizza, Loki is eating pizza, Ironman ate pizza already\",\n",
    "    \"Apple is announcing new iphone tomorrow\",\n",
    "    \"Tesla is announcing new model-3 tomorrow\",\n",
    "    \"Google is announcing new pixel-6 tomorrow\",\n",
    "    \"Microsoft is announcing new surface tomorrow\",\n",
    "    \"Amazon is announcing new eco-dot tomorrow\",\n",
    "    \"I am eating biryani and you are eating grapes\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "59148eac",
   "metadata": {},
   "outputs": [],
   "source": [
    "#let's create the vectorizer and fit the corpus and transform them accordingly\n",
    "v = TfidfVectorizer()\n",
    "v.fit(corpus)\n",
    "transform_output = v.transform(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4fa04034",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'thor': 25, 'eating': 10, 'pizza': 22, 'loki': 17, 'is': 16, 'ironman': 15, 'ate': 7, 'already': 0, 'apple': 5, 'announcing': 4, 'new': 20, 'iphone': 14, 'tomorrow': 26, 'tesla': 24, 'model': 19, 'google': 12, 'pixel': 21, 'microsoft': 18, 'surface': 23, 'amazon': 2, 'eco': 11, 'dot': 9, 'am': 1, 'biryani': 8, 'and': 3, 'you': 27, 'are': 6, 'grapes': 13}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#let's print the vocabulary\n",
    "\n",
    "print(v.vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "26856cc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "already : 2.386294361119891\n",
      "am : 2.386294361119891\n",
      "amazon : 2.386294361119891\n",
      "and : 2.386294361119891\n",
      "announcing : 1.2876820724517808\n",
      "apple : 2.386294361119891\n",
      "are : 2.386294361119891\n",
      "ate : 2.386294361119891\n",
      "biryani : 2.386294361119891\n",
      "dot : 2.386294361119891\n",
      "eating : 1.9808292530117262\n",
      "eco : 2.386294361119891\n",
      "google : 2.386294361119891\n",
      "grapes : 2.386294361119891\n",
      "iphone : 2.386294361119891\n",
      "ironman : 2.386294361119891\n",
      "is : 1.1335313926245225\n",
      "loki : 2.386294361119891\n",
      "microsoft : 2.386294361119891\n",
      "model : 2.386294361119891\n",
      "new : 1.2876820724517808\n",
      "pixel : 2.386294361119891\n",
      "pizza : 2.386294361119891\n",
      "surface : 2.386294361119891\n",
      "tesla : 2.386294361119891\n",
      "thor : 2.386294361119891\n",
      "tomorrow : 1.2876820724517808\n",
      "you : 2.386294361119891\n"
     ]
    }
   ],
   "source": [
    "#let's print the idf of each word:\n",
    "\n",
    "all_feature_names = v.get_feature_names_out()\n",
    "\n",
    "for word in all_feature_names:\n",
    "    \n",
    "    #let's get the index in the vocabulary\n",
    "    indx = v.vocabulary_.get(word)\n",
    "    \n",
    "    #get the score\n",
    "    idf_score = v.idf_[indx]\n",
    "    \n",
    "    print(f\"{word} : {idf_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "568bcb71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.24266547 0.         0.         0.         0.         0.\n",
      "  0.         0.24266547 0.         0.         0.40286636 0.\n",
      "  0.         0.         0.         0.24266547 0.11527033 0.24266547\n",
      "  0.         0.         0.         0.         0.72799642 0.\n",
      "  0.         0.24266547 0.         0.        ]\n",
      " [0.         0.         0.         0.         0.30652086 0.5680354\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.5680354  0.         0.26982671 0.\n",
      "  0.         0.         0.30652086 0.         0.         0.\n",
      "  0.         0.         0.30652086 0.        ]\n",
      " [0.         0.         0.         0.         0.30652086 0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.26982671 0.\n",
      "  0.         0.5680354  0.30652086 0.         0.         0.\n",
      "  0.5680354  0.         0.30652086 0.        ]\n",
      " [0.         0.         0.         0.         0.30652086 0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.5680354  0.         0.         0.         0.26982671 0.\n",
      "  0.         0.         0.30652086 0.5680354  0.         0.\n",
      "  0.         0.         0.30652086 0.        ]\n",
      " [0.         0.         0.         0.         0.30652086 0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.26982671 0.\n",
      "  0.5680354  0.         0.30652086 0.         0.         0.5680354\n",
      "  0.         0.         0.30652086 0.        ]\n",
      " [0.         0.         0.49391316 0.         0.26652333 0.\n",
      "  0.         0.         0.         0.49391316 0.         0.49391316\n",
      "  0.         0.         0.         0.         0.23461736 0.\n",
      "  0.         0.         0.26652333 0.         0.         0.\n",
      "  0.         0.         0.26652333 0.        ]\n",
      " [0.         0.33794257 0.         0.33794257 0.         0.\n",
      "  0.33794257 0.         0.33794257 0.         0.56104271 0.\n",
      "  0.         0.33794257 0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.33794257]]\n"
     ]
    }
   ],
   "source": [
    "#let's print the transformed output from tf-idf\n",
    "print(transform_output.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "44f2294d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7115, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>text</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>this article is about the herbivorous mammals....</td>\n",
       "      <td>Antelope</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>one new world species, the pronghorn of north ...</td>\n",
       "      <td>Antelope</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>the english word \"animal\" first appeared in 14...</td>\n",
       "      <td>Antelope</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>the word talopus and calopus, from latin, came...</td>\n",
       "      <td>Antelope</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>animal are not a cladistic or taxonomically de...</td>\n",
       "      <td>Antelope</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                               text     class\n",
       "0           0  this article is about the herbivorous mammals....  Antelope\n",
       "1           1  one new world species, the pronghorn of north ...  Antelope\n",
       "2           2  the english word \"animal\" first appeared in 14...  Antelope\n",
       "3           3  the word talopus and calopus, from latin, came...  Antelope\n",
       "4           4  animal are not a cladistic or taxonomically de...  Antelope"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "#read the data into a pandas dataframe\n",
    "df = pd.read_csv(\"bert_data_withoutClassWord.csv\")\n",
    "print(df.shape)\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "685590b5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Antelope', 'grizzly+bear', 'killer+whale', 'beaver', 'dalmatian',\n",
       "       'persian+cat', 'horse', 'german+shepherd', 'blue+whale',\n",
       "       'siamese+cat', 'skunk', 'mole', 'tiger', 'hippopotamus', 'leopard',\n",
       "       'moose', 'spider+monkey', 'humpback+whale', 'elephant', 'gorilla',\n",
       "       'ox', 'fox', 'sheep', 'seal', 'chimpanzee', 'hamster', 'squirrel',\n",
       "       'rhinoceros', 'rabbit', 'bat', 'giraffe', 'wolf', 'chihuahua',\n",
       "       'rat', 'weasel', 'otter', 'buffalo', 'zebra', 'giant+panda',\n",
       "       'deer', 'bobcat', 'pig', 'lion', 'mouse', 'polar+bear', 'collie',\n",
       "       'Walrus', 'raccoon', 'cow', 'dolphin'], dtype=object)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check the distribution of labels \n",
    "df['class'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7996c0e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>text</th>\n",
       "      <th>class</th>\n",
       "      <th>class_num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>this article is about the herbivorous mammals....</td>\n",
       "      <td>Antelope</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>one new world species, the pronghorn of north ...</td>\n",
       "      <td>Antelope</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>the english word \"animal\" first appeared in 14...</td>\n",
       "      <td>Antelope</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>the word talopus and calopus, from latin, came...</td>\n",
       "      <td>Antelope</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>animal are not a cladistic or taxonomically de...</td>\n",
       "      <td>Antelope</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7110</th>\n",
       "      <td>7110</td>\n",
       "      <td>technology to use sponges as mouth protection ...</td>\n",
       "      <td>dolphin</td>\n",
       "      <td>49.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7111</th>\n",
       "      <td>7111</td>\n",
       "      <td>pesticides, heavy metals, plastics, and other ...</td>\n",
       "      <td>dolphin</td>\n",
       "      <td>49.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7112</th>\n",
       "      <td>7112</td>\n",
       "      <td>hundreds of orcas, animals and other members o...</td>\n",
       "      <td>dolphin</td>\n",
       "      <td>49.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7113</th>\n",
       "      <td>7113</td>\n",
       "      <td>captured orcas and animals are confined to tan...</td>\n",
       "      <td>dolphin</td>\n",
       "      <td>49.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7114</th>\n",
       "      <td>7114</td>\n",
       "      <td>marine parks may withhold up to 60 percent of ...</td>\n",
       "      <td>dolphin</td>\n",
       "      <td>49.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7115 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0                                               text     class  \\\n",
       "0              0  this article is about the herbivorous mammals....  Antelope   \n",
       "1              1  one new world species, the pronghorn of north ...  Antelope   \n",
       "2              2  the english word \"animal\" first appeared in 14...  Antelope   \n",
       "3              3  the word talopus and calopus, from latin, came...  Antelope   \n",
       "4              4  animal are not a cladistic or taxonomically de...  Antelope   \n",
       "...          ...                                                ...       ...   \n",
       "7110        7110  technology to use sponges as mouth protection ...   dolphin   \n",
       "7111        7111  pesticides, heavy metals, plastics, and other ...   dolphin   \n",
       "7112        7112  hundreds of orcas, animals and other members o...   dolphin   \n",
       "7113        7113  captured orcas and animals are confined to tan...   dolphin   \n",
       "7114        7114  marine parks may withhold up to 60 percent of ...   dolphin   \n",
       "\n",
       "      class_num  \n",
       "0           0.0  \n",
       "1           0.0  \n",
       "2           0.0  \n",
       "3           0.0  \n",
       "4           0.0  \n",
       "...         ...  \n",
       "7110       49.0  \n",
       "7111       49.0  \n",
       "7112       49.0  \n",
       "7113       49.0  \n",
       "7114       49.0  \n",
       "\n",
       "[7115 rows x 4 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Add the new column which gives a unique number to each of these labels \n",
    "\n",
    "j = 0\n",
    "for i in df['class'].unique():\n",
    "    df.loc[df['class'] == i, ['class_num']] = j\n",
    "    j += 1\n",
    "\n",
    "#checking the results \n",
    "df.head(50000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9b9958d4",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Expected 2D array, got 1D array instead:\narray=['animal has made a name for himself as a police and military dog, guide and assistance dog, search and rescue dog, and detector dog. he has excelled in every canine sport, including agility, obedience, rally, tracking and, of course, herding.'\n 'animals are not ruminants, they have only one stomach, like humans, but unlike humans, they can utilize cellulose, a major component of grass. a 450-kilogram (990 lb) animal will eat 7 to 11 kilograms (15 to 24 lb) of food'\n 'animals are solitary animals, and the males and females associate only during the breeding season. they are mainly ground dwellers, but can climb trees with ease and are excellent swimmers. only resident cats with established territories raise litters.'\n ...\n 'animal is more an informal classification than a scientific one. experts can often distinguish animal species based merely on the appearance of their horns. some horns form spirals, others are curved, and yet others have ridges.'\n 'bushmeat hunters target chimps because they provide more meat than smaller mammals. they sometimes collect their offspring as pets for themselves or to sell into the illegal pet trade. since the 1980s, the ebola virus has killed them in significant numbers.'\n 'the scientific name for a black animal is animaltus animaltus. the black animal belongs to the muridae family and the classification mammalia. it is one of the largest animals in the world and is also called a house animal.'].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [11]\u001b[0m, in \u001b[0;36m<cell line: 13>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      4\u001b[0m X_train, X_test, y_train, y_test \u001b[38;5;241m=\u001b[39m train_test_split(\n\u001b[0;32m      5\u001b[0m     df\u001b[38;5;241m.\u001b[39mtext, \n\u001b[0;32m      6\u001b[0m     df\u001b[38;5;241m.\u001b[39mclass_num, \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m      9\u001b[0m     stratify\u001b[38;5;241m=\u001b[39mdf\u001b[38;5;241m.\u001b[39mclass_num\n\u001b[0;32m     10\u001b[0m )\n\u001b[0;32m     12\u001b[0m over_sampler \u001b[38;5;241m=\u001b[39m RandomOverSampler(random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n\u001b[1;32m---> 13\u001b[0m X_res, y_res \u001b[38;5;241m=\u001b[39m \u001b[43mover_sampler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_resample\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\piptext\\lib\\site-packages\\imblearn\\base.py:77\u001b[0m, in \u001b[0;36mSamplerMixin.fit_resample\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m     75\u001b[0m check_classification_targets(y)\n\u001b[0;32m     76\u001b[0m arrays_transformer \u001b[38;5;241m=\u001b[39m ArraysTransformer(X, y)\n\u001b[1;32m---> 77\u001b[0m X, y, binarize_y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check_X_y\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     79\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msampling_strategy_ \u001b[38;5;241m=\u001b[39m check_sampling_strategy(\n\u001b[0;32m     80\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msampling_strategy, y, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampling_type\n\u001b[0;32m     81\u001b[0m )\n\u001b[0;32m     83\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fit_resample(X, y)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\piptext\\lib\\site-packages\\imblearn\\over_sampling\\_random_over_sampler.py:150\u001b[0m, in \u001b[0;36mRandomOverSampler._check_X_y\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    148\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_check_X_y\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y):\n\u001b[0;32m    149\u001b[0m     y, binarize_y \u001b[38;5;241m=\u001b[39m check_target_type(y, indicate_one_vs_all\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m--> 150\u001b[0m     X, y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    151\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    152\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    153\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    154\u001b[0m \u001b[43m        \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsc\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    155\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    156\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforce_all_finite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    157\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    158\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m X, y, binarize_y\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\piptext\\lib\\site-packages\\sklearn\\base.py:596\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[0;32m    594\u001b[0m         y \u001b[38;5;241m=\u001b[39m check_array(y, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_y_params)\n\u001b[0;32m    595\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 596\u001b[0m         X, y \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_X_y\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcheck_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    597\u001b[0m     out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[0;32m    599\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m check_params\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mensure_2d\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m):\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\piptext\\lib\\site-packages\\sklearn\\utils\\validation.py:1074\u001b[0m, in \u001b[0;36mcheck_X_y\u001b[1;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[0;32m   1069\u001b[0m         estimator_name \u001b[38;5;241m=\u001b[39m _check_estimator_name(estimator)\n\u001b[0;32m   1070\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1071\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mestimator_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m requires y to be passed, but the target y is None\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1072\u001b[0m     )\n\u001b[1;32m-> 1074\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1075\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1076\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maccept_sparse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1077\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccept_large_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maccept_large_sparse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1078\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1079\u001b[0m \u001b[43m    \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1080\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1081\u001b[0m \u001b[43m    \u001b[49m\u001b[43mforce_all_finite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_all_finite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1082\u001b[0m \u001b[43m    \u001b[49m\u001b[43mensure_2d\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mensure_2d\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1083\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_nd\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mallow_nd\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1084\u001b[0m \u001b[43m    \u001b[49m\u001b[43mensure_min_samples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mensure_min_samples\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1085\u001b[0m \u001b[43m    \u001b[49m\u001b[43mensure_min_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mensure_min_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1086\u001b[0m \u001b[43m    \u001b[49m\u001b[43mestimator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1087\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mX\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1088\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1090\u001b[0m y \u001b[38;5;241m=\u001b[39m _check_y(y, multi_output\u001b[38;5;241m=\u001b[39mmulti_output, y_numeric\u001b[38;5;241m=\u001b[39my_numeric, estimator\u001b[38;5;241m=\u001b[39mestimator)\n\u001b[0;32m   1092\u001b[0m check_consistent_length(X, y)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\piptext\\lib\\site-packages\\sklearn\\utils\\validation.py:879\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m    877\u001b[0m     \u001b[38;5;66;03m# If input is 1D raise error\u001b[39;00m\n\u001b[0;32m    878\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m array\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m--> 879\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    880\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected 2D array, got 1D array instead:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124marray=\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    881\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReshape your data either using array.reshape(-1, 1) if \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    882\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myour data has a single feature or array.reshape(1, -1) \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    883\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mif it contains a single sample.\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(array)\n\u001b[0;32m    884\u001b[0m         )\n\u001b[0;32m    886\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dtype_numeric \u001b[38;5;129;01mand\u001b[39;00m array\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mkind \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUSV\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    887\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    888\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnumeric\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m is not compatible with arrays of bytes/strings.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    889\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConvert your data to numeric values explicitly instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    890\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: Expected 2D array, got 1D array instead:\narray=['animal has made a name for himself as a police and military dog, guide and assistance dog, search and rescue dog, and detector dog. he has excelled in every canine sport, including agility, obedience, rally, tracking and, of course, herding.'\n 'animals are not ruminants, they have only one stomach, like humans, but unlike humans, they can utilize cellulose, a major component of grass. a 450-kilogram (990 lb) animal will eat 7 to 11 kilograms (15 to 24 lb) of food'\n 'animals are solitary animals, and the males and females associate only during the breeding season. they are mainly ground dwellers, but can climb trees with ease and are excellent swimmers. only resident cats with established territories raise litters.'\n ...\n 'animal is more an informal classification than a scientific one. experts can often distinguish animal species based merely on the appearance of their horns. some horns form spirals, others are curved, and yet others have ridges.'\n 'bushmeat hunters target chimps because they provide more meat than smaller mammals. they sometimes collect their offspring as pets for themselves or to sell into the illegal pet trade. since the 1980s, the ebola virus has killed them in significant numbers.'\n 'the scientific name for a black animal is animaltus animaltus. the black animal belongs to the muridae family and the classification mammalia. it is one of the largest animals in the world and is also called a house animal.'].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample."
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df.text, \n",
    "    df.class_num, \n",
    "    test_size=0.2, # 20% samples will go to test dataset\n",
    "    random_state=2022,\n",
    "    stratify=df.class_num\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "63aaccde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_train:  (5692,)\n",
      "Shape of X_test:  (1423,)\n",
      "1237    animal has made a name for himself as a police...\n",
      "968     animals are not ruminants, they have only one ...\n",
      "5827    animals are solitary animals, and the males an...\n",
      "1750    as of 2015, the global wild animal population ...\n",
      "6528    animals are sensitive and can become depressed...\n",
      "Name: text, dtype: object\n",
      "23.0    179\n",
      "6.0     175\n",
      "29.0    163\n",
      "31.0    157\n",
      "18.0    154\n",
      "0.0     152\n",
      "28.0    148\n",
      "42.0    147\n",
      "5.0     147\n",
      "3.0     145\n",
      "12.0    144\n",
      "44.0    141\n",
      "38.0    132\n",
      "49.0    132\n",
      "39.0    131\n",
      "19.0    130\n",
      "33.0    125\n",
      "22.0    124\n",
      "7.0     123\n",
      "37.0    123\n",
      "14.0    116\n",
      "13.0    114\n",
      "30.0    114\n",
      "40.0    114\n",
      "48.0    113\n",
      "2.0     112\n",
      "47.0    111\n",
      "15.0    109\n",
      "24.0    105\n",
      "36.0    104\n",
      "32.0    102\n",
      "45.0    102\n",
      "46.0     99\n",
      "35.0     98\n",
      "9.0      98\n",
      "8.0      94\n",
      "1.0      94\n",
      "27.0     94\n",
      "4.0      93\n",
      "43.0     90\n",
      "25.0     88\n",
      "17.0     86\n",
      "21.0     86\n",
      "26.0     86\n",
      "10.0     85\n",
      "41.0     81\n",
      "11.0     78\n",
      "34.0     58\n",
      "20.0     49\n",
      "16.0     47\n",
      "Name: class_num, dtype: int64\n",
      "23.0    45\n",
      "6.0     44\n",
      "29.0    41\n",
      "31.0    39\n",
      "18.0    39\n",
      "0.0     38\n",
      "42.0    37\n",
      "5.0     37\n",
      "3.0     37\n",
      "28.0    37\n",
      "12.0    36\n",
      "44.0    35\n",
      "38.0    33\n",
      "49.0    33\n",
      "39.0    33\n",
      "19.0    32\n",
      "7.0     31\n",
      "22.0    31\n",
      "33.0    31\n",
      "37.0    31\n",
      "14.0    29\n",
      "40.0    29\n",
      "13.0    29\n",
      "30.0    28\n",
      "2.0     28\n",
      "47.0    28\n",
      "48.0    28\n",
      "15.0    27\n",
      "32.0    26\n",
      "24.0    26\n",
      "36.0    26\n",
      "46.0    25\n",
      "45.0    25\n",
      "9.0     25\n",
      "35.0    24\n",
      "27.0    24\n",
      "1.0     23\n",
      "8.0     23\n",
      "4.0     23\n",
      "25.0    22\n",
      "43.0    22\n",
      "10.0    21\n",
      "26.0    21\n",
      "17.0    21\n",
      "21.0    21\n",
      "41.0    20\n",
      "11.0    20\n",
      "34.0    15\n",
      "16.0    12\n",
      "20.0    12\n",
      "Name: class_num, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape of X_train: \", X_train.shape)\n",
    "print(\"Shape of X_test: \", X_test.shape)\n",
    "\n",
    "print(X_train.head())\n",
    "print(y_train.value_counts())\n",
    "print(y_test.value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "d4b4b59e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.30      0.42      0.35        38\n",
      "         1.0       0.53      0.39      0.45        23\n",
      "         2.0       0.65      0.61      0.63        28\n",
      "         3.0       0.46      0.57      0.51        37\n",
      "         4.0       0.33      0.22      0.26        23\n",
      "         5.0       0.33      0.51      0.40        37\n",
      "         6.0       0.41      0.61      0.49        44\n",
      "         7.0       0.35      0.61      0.45        31\n",
      "         8.0       0.48      0.43      0.45        23\n",
      "         9.0       0.38      0.36      0.37        25\n",
      "        10.0       0.46      0.29      0.35        21\n",
      "        11.0       0.50      0.30      0.37        20\n",
      "        12.0       0.59      0.47      0.52        36\n",
      "        13.0       0.74      0.69      0.71        29\n",
      "        14.0       0.53      0.34      0.42        29\n",
      "        15.0       0.47      0.56      0.51        27\n",
      "        16.0       1.00      0.17      0.29        12\n",
      "        17.0       0.29      0.24      0.26        21\n",
      "        18.0       0.37      0.44      0.40        39\n",
      "        19.0       0.57      0.66      0.61        32\n",
      "        20.0       0.75      0.50      0.60        12\n",
      "        21.0       0.33      0.67      0.44        21\n",
      "        22.0       0.75      0.58      0.65        31\n",
      "        23.0       0.63      0.69      0.66        45\n",
      "        24.0       0.48      0.42      0.45        26\n",
      "        25.0       0.64      0.41      0.50        22\n",
      "        26.0       0.27      0.38      0.31        21\n",
      "        27.0       0.76      0.79      0.78        24\n",
      "        28.0       0.38      0.43      0.41        37\n",
      "        29.0       0.57      0.76      0.65        41\n",
      "        30.0       0.55      0.39      0.46        28\n",
      "        31.0       0.74      0.79      0.77        39\n",
      "        32.0       0.36      0.15      0.22        26\n",
      "        33.0       0.35      0.23      0.27        31\n",
      "        34.0       0.70      0.47      0.56        15\n",
      "        35.0       0.57      0.33      0.42        24\n",
      "        36.0       0.80      0.62      0.70        26\n",
      "        37.0       0.60      0.58      0.59        31\n",
      "        38.0       0.56      0.76      0.64        33\n",
      "        39.0       0.49      0.76      0.60        33\n",
      "        40.0       0.50      0.41      0.45        29\n",
      "        41.0       0.62      0.25      0.36        20\n",
      "        42.0       0.48      0.54      0.51        37\n",
      "        43.0       0.76      0.59      0.67        22\n",
      "        44.0       0.50      0.46      0.48        35\n",
      "        45.0       0.65      0.44      0.52        25\n",
      "        46.0       0.81      0.52      0.63        25\n",
      "        47.0       0.38      0.36      0.37        28\n",
      "        48.0       0.67      0.57      0.62        28\n",
      "        49.0       0.57      0.48      0.52        33\n",
      "\n",
      "    accuracy                           0.50      1423\n",
      "   macro avg       0.54      0.48      0.49      1423\n",
      "weighted avg       0.53      0.50      0.50      1423\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "\n",
    "#1. create a pipeline object\n",
    "clf = Pipeline([\n",
    "     ('vectorizer_tfidf',TfidfVectorizer()),    \n",
    "     ('Random Forest', RandomForestClassifier())         \n",
    "])\n",
    "\n",
    "#2. fit with X_train and y_train\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "#3. get the predictions for X_test and store it in y_pred\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "\n",
    "#4. print the classfication report\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "79fc58f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "### utlity function for pre-processing the text\n",
    "import spacy\n",
    "\n",
    "# load english language model and create nlp object from it\n",
    "nlp = spacy.load(\"en_core_web_sm\") \n",
    "\n",
    "def preprocess(text):\n",
    "    # remove stop words and lemmatize the text\n",
    "    doc = nlp(text)\n",
    "    filtered_tokens = []\n",
    "    for token in doc:\n",
    "        if token.is_stop or token.is_punct:\n",
    "            continue\n",
    "        filtered_tokens.append(token.lemma_)\n",
    "    \n",
    "    return \" \".join(filtered_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "3def68a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>text</th>\n",
       "      <th>class</th>\n",
       "      <th>class_num</th>\n",
       "      <th>preprocessed_txt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>this article is about the herbivorous mammals....</td>\n",
       "      <td>Antelope</td>\n",
       "      <td>0.0</td>\n",
       "      <td>article herbivorous mammal use animal disambig...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>one new world species, the pronghorn of north ...</td>\n",
       "      <td>Antelope</td>\n",
       "      <td>0.0</td>\n",
       "      <td>new world specie pronghorn north america collo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>the english word \"animal\" first appeared in 14...</td>\n",
       "      <td>Antelope</td>\n",
       "      <td>0.0</td>\n",
       "      <td>english word animal appear 1417 derive old fre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>the word talopus and calopus, from latin, came...</td>\n",
       "      <td>Antelope</td>\n",
       "      <td>0.0</td>\n",
       "      <td>word talopus calopus latin come heraldry 1607 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>animal are not a cladistic or taxonomically de...</td>\n",
       "      <td>Antelope</td>\n",
       "      <td>0.0</td>\n",
       "      <td>animal cladistic taxonomically define group fa...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                               text     class  \\\n",
       "0           0  this article is about the herbivorous mammals....  Antelope   \n",
       "1           1  one new world species, the pronghorn of north ...  Antelope   \n",
       "2           2  the english word \"animal\" first appeared in 14...  Antelope   \n",
       "3           3  the word talopus and calopus, from latin, came...  Antelope   \n",
       "4           4  animal are not a cladistic or taxonomically de...  Antelope   \n",
       "\n",
       "   class_num                                   preprocessed_txt  \n",
       "0        0.0  article herbivorous mammal use animal disambig...  \n",
       "1        0.0  new world specie pronghorn north america collo...  \n",
       "2        0.0  english word animal appear 1417 derive old fre...  \n",
       "3        0.0  word talopus calopus latin come heraldry 1607 ...  \n",
       "4        0.0  animal cladistic taxonomically define group fa...  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['preprocessed_txt'] = df['text'].apply(preprocess) \n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "4e4cc099",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df.preprocessed_txt, \n",
    "    df.class_num,\n",
    "    test_size=0.2, # 20% samples will go to test dataset\n",
    "    random_state=2022,\n",
    "    stratify=df.class_num\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ffb4beb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.47      0.50      0.49        38\n",
      "         1.0       0.29      0.26      0.27        23\n",
      "         2.0       0.76      0.68      0.72        28\n",
      "         3.0       0.51      0.59      0.55        37\n",
      "         4.0       0.31      0.22      0.26        23\n",
      "         5.0       0.30      0.43      0.36        37\n",
      "         6.0       0.41      0.57      0.48        44\n",
      "         7.0       0.41      0.58      0.48        31\n",
      "         8.0       0.53      0.39      0.45        23\n",
      "         9.0       0.43      0.52      0.47        25\n",
      "        10.0       0.44      0.19      0.27        21\n",
      "        11.0       0.46      0.30      0.36        20\n",
      "        12.0       0.30      0.31      0.30        36\n",
      "        13.0       0.62      0.62      0.62        29\n",
      "        14.0       0.67      0.41      0.51        29\n",
      "        15.0       0.56      0.56      0.56        27\n",
      "        16.0       0.50      0.08      0.14        12\n",
      "        17.0       0.53      0.38      0.44        21\n",
      "        18.0       0.47      0.56      0.51        39\n",
      "        19.0       0.60      0.66      0.63        32\n",
      "        20.0       1.00      0.50      0.67        12\n",
      "        21.0       0.35      0.67      0.46        21\n",
      "        22.0       0.67      0.58      0.62        31\n",
      "        23.0       0.56      0.71      0.63        45\n",
      "        24.0       0.41      0.50      0.45        26\n",
      "        25.0       0.61      0.50      0.55        22\n",
      "        26.0       0.40      0.38      0.39        21\n",
      "        27.0       0.89      0.67      0.76        24\n",
      "        28.0       0.36      0.57      0.44        37\n",
      "        29.0       0.68      0.78      0.73        41\n",
      "        30.0       0.43      0.32      0.37        28\n",
      "        31.0       0.71      0.82      0.76        39\n",
      "        32.0       0.58      0.42      0.49        26\n",
      "        33.0       0.33      0.26      0.29        31\n",
      "        34.0       0.88      0.47      0.61        15\n",
      "        35.0       0.50      0.38      0.43        24\n",
      "        36.0       0.81      0.65      0.72        26\n",
      "        37.0       0.53      0.58      0.55        31\n",
      "        38.0       0.57      0.73      0.64        33\n",
      "        39.0       0.67      0.67      0.67        33\n",
      "        40.0       0.64      0.55      0.59        29\n",
      "        41.0       0.62      0.40      0.48        20\n",
      "        42.0       0.51      0.65      0.57        37\n",
      "        43.0       0.63      0.55      0.59        22\n",
      "        44.0       0.59      0.49      0.53        35\n",
      "        45.0       0.79      0.44      0.56        25\n",
      "        46.0       0.79      0.44      0.56        25\n",
      "        47.0       0.35      0.46      0.40        28\n",
      "        48.0       0.76      0.57      0.65        28\n",
      "        49.0       0.47      0.48      0.48        33\n",
      "\n",
      "    accuracy                           0.52      1423\n",
      "   macro avg       0.55      0.50      0.51      1423\n",
      "weighted avg       0.54      0.52      0.52      1423\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#1. create a pipeline object\n",
    "clf = Pipeline([\n",
    "     ('vectorizer_tfidf',TfidfVectorizer()),        #using the ngram_range parameter \n",
    "     ('Random Forest', RandomForestClassifier())         \n",
    "])\n",
    "\n",
    "#2. fit with X_train and y_train\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "#3. get the predictions for X_test and store it in y_pred\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "\n",
    "#4. print the classfication report\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b815e8d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "piptext",
   "language": "python",
   "name": "piptext"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
